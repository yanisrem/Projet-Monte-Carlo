{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.densite_function import *\n",
    "from src.gaussian_simulation import *\n",
    "from src.estimators import *\n",
    "from src.vraisemblance import *\n",
    "import numpy as np\n",
    "from numpy.linalg import norm \n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8878)\n",
    "\n",
    "theta=simulate_gaussian_vector(mu=np.array([0]*20), sigma=np.identity(20))\n",
    "\n",
    "A_optimal=np.matrix(np.identity(20))*0.5\n",
    "b_optimal=theta/2\n",
    "\n",
    "A=A_optimal+simulate_gaussian_vector(mu=np.array([0]*20), sigma=0.01*np.identity(20))\n",
    "b=b_optimal+simulate_gaussian_vector(mu=np.array([0]*20), sigma=0.01*np.identity(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On généré un n-échantillon de taille 100, de loi $p_{\\theta}(\\mathbf{x})=\\mathcal{N}(\\theta, 2I_{20})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8878)\n",
    "\n",
    "def generer_nech_gaussien(n):\n",
    "    i=1\n",
    "    echantillon_x=np.array([])\n",
    "\n",
    "    while i<=n:\n",
    "        if i==1:\n",
    "            echantillon_x=np.append(echantillon_x, simulate_gaussian_vector(mu=theta, sigma=2*np.identity(20)))\n",
    "        else:\n",
    "            echantillon_x=np.vstack((echantillon_x, simulate_gaussian_vector(mu=theta, sigma=2*np.identity(20))))\n",
    "        i+=1\n",
    "    return echantillon_x\n",
    "\n",
    "echantillon_x=generer_nech_gaussien(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La log-vraisemblance de l'échantillon (avec le facteur $-\\frac{1}{n}$) est $l_n(\\theta)=\\frac{1}{n}\\sum_{i=1}^n \\lVert X_i - \\theta \\rVert^2 = \\frac{1}{n}\\sum_{i=1}^n l_i(\\theta) $. \n",
    "On cherche $\\hat{\\theta} \\in argmin \\; l_n(\\theta)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On estime le theta de la log vraisemblance par $\\nabla_{\\theta} l_i(\\theta)= -2(X_i-\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG(theta_init, learn_rate, echantillon, n_iter):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta_init)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_IAWE(theta_init, learn_rate, n_iter, A, b, echantillon, k=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta_init, A=A, b=b, x=echantillon[i])\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta, A=A, b=b, x=echantillon[i])\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta, A=A, b=b, x=echantillon[i])\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_SUMO(theta_init, learn_rate, n_iter, A, b, echantillon, l=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta_init, A=A, b=b, x=echantillon[i], r=0.6, l=l)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta, A=A, b=b, x=echantillon[i], r=0.6, l=l)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta, A=A, b=b, x=echantillon[i], r=0.6, l=l)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_RR(theta_init, learn_rate, n_iter, A, b, echantillon, l=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta_init, A=A, b=b, r=0.6, l=l)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, l=l)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, l=l)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_SS(theta_init, learn_rate, n_iter, A, b, echantillon, l=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta_init, A=A, b=b, r=0.6, l=l)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, l=l)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, l=l)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vraie valeur de theta: [-0.3  -1.01 -0.57  0.53 -0.45 -1.65 -1.66  1.26 -0.5  -2.16  0.18 -0.7\n",
      " -0.77  0.53  0.12 -0.5   0.69 -0.35 -0.43  1.35]\n",
      "Estimation de theta par descente de gradient stochastique useuelle: [-0.03 -1.04 -0.47  0.34 -0.31 -1.87 -1.52  1.08 -0.37 -1.68  0.29 -0.6\n",
      " -0.58  0.56  0.16 -0.41  0.55 -0.33 -0.33  1.33]\n",
      "Estimation de theta par SDG IWAE: [ 0.43  1.9   0.95 -0.43  0.58  2.79  2.31 -1.19  0.73  2.83 -0.18  1.18\n",
      "  1.31 -0.49 -0.02  0.94 -0.81  0.52  0.89 -1.75]\n",
      "Estimation de theta par SDG SUMO: [ 0.36  1.99  0.27 -0.68  0.49  2.48  2.44 -0.47  0.76  2.46  0.1   1.11\n",
      "  1.72 -0.22  0.42  0.59 -0.28  0.75  0.91 -2.04]\n",
      "Estimation de theta par SDG RR: [-7.86  0.44 -0.76 -3.34 -0.93  1.5   1.48 -4.38 -0.88  2.56 -3.24 -0.83\n",
      " -0.58 -3.48 -2.52 -1.38 -3.53 -1.3  -1.18 -4.79]\n",
      "Estimation de theta par SDG SS: [-23.44   3.57   2.96  -3.76  -0.11   7.28   9.04  -4.26   5.74   8.91\n",
      "  -4.93   3.28   6.11  -3.8   -2.04   2.04  -3.52   0.14   5.32  -5.92]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(878)\n",
    "theta_sdg=SDG(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, echantillon=echantillon_x)\n",
    "theta_iawe=SDG_IAWE(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k=6)\n",
    "theta_SUMO=SDG_SUMO(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=6)\n",
    "theta_RR=SDG_RR(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=6)\n",
    "theta_SS=SDG_SS(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=6)\n",
    "\n",
    "print(\"Vraie valeur de theta: {}\".format(np.around(theta, 2)))\n",
    "print(\"Estimation de theta par descente de gradient stochastique useuelle: {}\".format(np.around(theta_sdg, 2)))\n",
    "print(\"Estimation de theta par SDG IWAE: {}\".format(np.around(theta_iawe, 2)))\n",
    "print(\"Estimation de theta par SDG SUMO: {}\".format(np.around(theta_SUMO, 2)))\n",
    "print(\"Estimation de theta par SDG RR: {}\".format(np.around(theta_RR, 2)))\n",
    "print(\"Estimation de theta par SDG SS: {}\".format(np.around(theta_SS, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedure_MC_theta(M, L, theta, A, b, n):\n",
    "    biais_SDG_M={}\n",
    "    biais_IWAE_M={}\n",
    "    biais_SUMO_M={}\n",
    "    biais_SS_M={}\n",
    "    biais_RR_M={}\n",
    "\n",
    "    var_SDG_M={}\n",
    "    var_IWAE_M={}\n",
    "    var_SUMO_M={}\n",
    "    var_SS_M={}\n",
    "    var_RR_M={}\n",
    "\n",
    "    l=1\n",
    "    while l<=L:\n",
    "        print(l)\n",
    "        m=1\n",
    "        estimations_SDG_M_l=np.array([])\n",
    "        estimations_IWAE_M_l=np.array([])\n",
    "        estimations_SUMO_M_l=np.array([])\n",
    "        estimations_SS_M_l=np.array([])\n",
    "        estimations_RR_M_l=np.array([])\n",
    "\n",
    "\n",
    "        while m<=M:\n",
    "            echantillon_x=generer_nech_gaussien(n)\n",
    "            theta_SDG=SDG(theta_init=np.array([0]*20), learn_rate=0.01, echantillon=echantillon_x, n_iter=100)\n",
    "            theta_IAWE=SDG_IAWE(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k=l)\n",
    "            theta_SUMO=SDG_SUMO(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "            theta_RR=SDG_RR(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "            theta_SS=SDG_SS(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "\n",
    "            if m==1:\n",
    "                estimations_SDG_M_l=np.append(estimations_SDG_M_l, theta_SDG)\n",
    "                estimations_IWAE_M_l= np.append(estimations_IWAE_M_l, theta_IAWE)\n",
    "                estimations_SUMO_M_l=np.append(estimations_SUMO_M_l, theta_SUMO)\n",
    "                estimations_RR_M_l=np.append(estimations_RR_M_l, theta_RR)\n",
    "                estimations_SS_M_l=np.append(estimations_SS_M_l, theta_SS)\n",
    "            \n",
    "            else:\n",
    "                estimations_SDG_M_l=np.vstack((estimations_SDG_M_l, theta_SDG))\n",
    "                estimations_IWAE_M_l= np.vstack((estimations_IWAE_M_l, theta_IAWE))\n",
    "                estimations_SUMO_M_l=np.vstack((estimations_SUMO_M_l, theta_SUMO))\n",
    "                estimations_RR_M_l=np.vstack((estimations_RR_M_l, theta_RR))\n",
    "                estimations_SS_M_l=np.vstack((estimations_SS_M_l, theta_SS))\n",
    "            m+=1\n",
    "\n",
    "        biais_SDG_M_l=np.mean(estimations_SDG_M_l, axis=0)-theta\n",
    "        biais_IWAE_M_l=np.mean(estimations_IWAE_M_l, axis=0)-theta\n",
    "        biais_IWAE_M_l=np.mean(estimations_IWAE_M_l, axis=0)-theta\n",
    "        biais_SUMO_M_l=np.mean(estimations_SUMO_M_l, axis=0)-theta\n",
    "        biais_SS_M_l=np.mean(estimations_SS_M_l, axis=0)-theta\n",
    "        biais_RR_M_l=np.mean(estimations_RR_M_l, axis=0)-theta\n",
    "\n",
    "        squared_biais_SDG_M_l=norm(biais_SDG_M_l)**2\n",
    "        squared_biais_IWAE_M_l=norm(biais_IWAE_M_l)**2\n",
    "        squared_biais_SUMO_M_l=norm(biais_SUMO_M_l)**2\n",
    "        squared_biais_SS_M_l=norm(biais_SS_M_l)**2\n",
    "        squared_biais_RR_M_l=norm(biais_RR_M_l)**2\n",
    "\n",
    "        var_SDG_M_l=np.mean(norm(estimations_SDG_M_l-np.mean(estimations_IWAE_M_l, axis=0))**2)\n",
    "        var_IWAE_M_l=np.mean(norm(estimations_IWAE_M_l-np.mean(estimations_IWAE_M_l, axis=0))**2)\n",
    "        var_SUMO_M_l=np.mean(norm(estimations_SUMO_M_l-np.mean(estimations_SUMO_M_l, axis=0))**2)\n",
    "        var_SS_M_l=np.mean(norm(estimations_SS_M_l-np.mean(estimations_SS_M_l, axis=0))**2)\n",
    "        var_RR_M_l=np.mean(norm(estimations_RR_M_l-np.mean(estimations_RR_M_l, axis=0))**2)\n",
    "        \n",
    "        biais_SDG_M[l]=squared_biais_SDG_M_l\n",
    "        biais_IWAE_M[l]=squared_biais_IWAE_M_l\n",
    "        biais_SUMO_M[l]=squared_biais_SUMO_M_l\n",
    "        biais_SS_M[l]=squared_biais_SS_M_l\n",
    "        biais_RR_M[l]=squared_biais_RR_M_l\n",
    "        \n",
    "        var_SDG_M[l]=var_SDG_M_l\n",
    "        var_IWAE_M[l]=var_IWAE_M_l\n",
    "        var_SUMO_M[l]=var_SUMO_M_l\n",
    "        var_SS_M[l]=var_SS_M_l\n",
    "        var_RR_M[l]=var_RR_M_l\n",
    "\n",
    "        l+=1\n",
    "\n",
    "    return biais_SDG_M, biais_IWAE_M, biais_SUMO_M, biais_SS_M, biais_RR_M, var_SDG_M,var_IWAE_M, var_SUMO_M, var_SS_M, var_RR_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yanis\\OneDrive\\Documents\\Monte Carlo\\Projet-Monte-Carlo\\src\\estimators.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return num/denom-theta\n",
      "c:\\Users\\yanis\\OneDrive\\Documents\\Monte Carlo\\Projet-Monte-Carlo\\src\\estimators.py:251: RuntimeWarning: invalid value encountered in true_divide\n",
      "  IWAE_O=np.sum(np.array([w_i*z_i for (w_i,z_i) in zip(array_w_O,z_O)]), axis=0)/np.sum(array_w_O)-theta\n",
      "c:\\Users\\yanis\\OneDrive\\Documents\\Monte Carlo\\Projet-Monte-Carlo\\src\\estimators.py:252: RuntimeWarning: invalid value encountered in true_divide\n",
      "  IWAE_E=np.sum(np.array([w_i*z_i for (w_i,z_i) in zip(array_w_E,z_E)]), axis=0)/np.sum(array_w_E)-theta\n",
      "c:\\Users\\yanis\\OneDrive\\Documents\\Monte Carlo\\Projet-Monte-Carlo\\src\\estimators.py:253: RuntimeWarning: invalid value encountered in true_divide\n",
      "  IWAE_OUE=np.sum(np.array([w_i*z_i for (w_i,z_i) in zip(array_w,z)]), axis=0)/np.sum(array_w)-theta\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_116392\\420352767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8554\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m biais_SDG_M_theta, biais_IWAE_M_theta, biais_SUMO_M_theta, biais_SS_M_theta, biais_RR_M_theta, var_SDG_M_theta, var_IWAE_M_theta, var_SUMO_M_theta, var_SS_M_theta, var_RR_M_theta = procedure_MC_theta(M=1000, \n\u001b[0m\u001b[0;32m      4\u001b[0m                                                                                                                                                                                                         \u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                                                                                                                                                         \u001b[0mtheta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_116392\\3770226785.py\u001b[0m in \u001b[0;36mprocedure_MC_theta\u001b[1;34m(M, L, theta, A, b, n)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mtheta_SUMO\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSDG_SUMO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mechantillon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mechantillon_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mtheta_RR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSDG_RR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mechantillon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mechantillon_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mtheta_SS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSDG_SS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mechantillon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mechantillon_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_116392\\551645023.py\u001b[0m in \u001b[0;36mSDG_SS\u001b[1;34m(theta_init, learn_rate, n_iter, A, b, echantillon, l)\u001b[0m\n\u001b[0;32m     20\u001b[0m            \u001b[0mcompteur\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mtheta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mestimateur_ML_SS_gradientlogvraisemblance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mechantillon\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mcompteur\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yanis\\OneDrive\\Documents\\Monte Carlo\\Projet-Monte-Carlo\\src\\estimators.py\u001b[0m in \u001b[0;36mestimateur_ML_SS_gradientlogvraisemblance\u001b[1;34m(x, theta, A, b, r, l)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[0mz_O\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_O\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_i_O\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m             \u001b[0mz_E\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_E\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_i_E\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(8554)\n",
    "\n",
    "biais_SDG_M_theta, biais_IWAE_M_theta, biais_SUMO_M_theta, biais_SS_M_theta, biais_RR_M_theta, var_SDG_M_theta, var_IWAE_M_theta, var_SUMO_M_theta, var_SS_M_theta, var_RR_M_theta = procedure_MC_theta(M=1000, \n",
    "                                                                                                                                                                                                        L=6, \n",
    "                                                                                                                                                                                                        theta=theta, \n",
    "                                                                                                                                                                                                        A=A, \n",
    "                                                                                                                                                                                                        b=b,\n",
    "                                                                                                                                                                                                        n=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
