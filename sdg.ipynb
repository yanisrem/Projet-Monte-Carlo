{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.densite_function import *\n",
    "from src.gaussian_simulation import *\n",
    "from src.estimators2 import *\n",
    "from src.vraisemblance import *\n",
    "import numpy as np\n",
    "from numpy.linalg import norm \n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8878)\n",
    "\n",
    "theta=simulate_gaussian_vector(mu=np.array([0]*20), sigma=np.identity(20))\n",
    "z=simulate_gaussian_vector(mu=theta, sigma=np.identity(20))\n",
    "x=simulate_gaussian_vector(mu=z, sigma=np.identity(20)) #on sait simuler x|z\n",
    "\n",
    "#x=simulate_gaussian_vector(mu=theta, sigma=2*np.identity(20))\n",
    "\n",
    "A_optimal=np.matrix(np.identity(20))*0.5\n",
    "b_optimal=theta/2\n",
    "\n",
    "A=A_optimal+simulate_gaussian_vector(mu=np.array([0]*20), sigma=0.01*np.identity(20))\n",
    "b=b_optimal+simulate_gaussian_vector(mu=np.array([0]*20), sigma=0.01*np.identity(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On généré un n-échantillon de taille 100, de loi $p_{\\theta}(\\mathbf{x}|z)=\\mathcal{N}(z, I_{20})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8878)\n",
    "\n",
    "def generer_nech_gaussien(n):\n",
    "    i=1\n",
    "    echantillon_x=np.array([])\n",
    "\n",
    "    while i<=n:\n",
    "        z=simulate_gaussian_vector(mu=theta, sigma=np.identity(20))\n",
    "        if i==1:\n",
    "            echantillon_x=np.append(echantillon_x, simulate_gaussian_vector(mu=z, sigma=np.identity(20))) #on sait simuler x|z\n",
    "        else:\n",
    "            echantillon_x=np.vstack((echantillon_x, simulate_gaussian_vector(mu=z, sigma=np.identity(20))))\n",
    "        i+=1\n",
    "    return echantillon_x\n",
    "\n",
    "echantillon_x=generer_nech_gaussien(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La log-vraisemblance de l'échantillon (avec le facteur $-\\frac{1}{n}$) est $l_n(\\theta)=\\frac{1}{n}\\sum_{i=1}^n \\lVert X_i - \\theta \\rVert^2 = \\frac{1}{n}\\sum_{i=1}^n l_i(\\theta) $. \n",
    "On cherche $\\hat{\\theta} \\in argmin \\; l_n(\\theta)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On estime le theta de la log vraisemblance par $\\nabla_{\\theta} l_i(\\theta)= -2(X_i-\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG(theta_init, learn_rate, echantillon, n_iter):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta_init)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_IAWE(theta_init, learn_rate, n_iter, A, b, echantillon, k=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta_init, A=A, b=b, x=echantillon[i])\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta, A=A, b=b, x=echantillon[i])\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta, A=A, b=b, x=echantillon[i])\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_SUMO(theta_init, learn_rate, n_iter, A, b, echantillon, k_max=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta_init, A=A, b=b, x=echantillon[i], r=0.6, k_max=k_max)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta, A=A, b=b, x=echantillon[i], r=0.6, k_max=k_max)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta, A=A, b=b, x=echantillon[i], r=0.6, k_max=k_max)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_RR(theta_init, learn_rate, n_iter, A, b, echantillon, k_max=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta_init, A=A, b=b, r=0.6, k_max=k_max)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, k_max=k_max)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, k_max=k_max)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_SS(theta_init, learn_rate, n_iter, A, b, echantillon, k_max=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta_init, A=A, b=b, r=0.6, k_max=k_max)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, k_max=k_max)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, k_max=k_max)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vraie valeur de theta: [-0.3  -1.01 -0.57  0.53 -0.45 -1.65 -1.66  1.26 -0.5  -2.16  0.18 -0.7\n",
      " -0.77  0.53  0.12 -0.5   0.69 -0.35 -0.43  1.35]\n",
      "Estimation de theta par descente de gradient stochastique useuelle: [-0.2  -0.83 -0.48  0.36 -0.49 -1.79 -1.34  1.06 -0.31 -1.59  0.25 -0.65\n",
      " -0.67  0.57  0.08 -0.27  0.52 -0.37 -0.22  1.07]\n",
      "Estimation de theta par SDG IWAE: [ 0.15  1.43  0.64 -1.    0.53  2.28  1.87 -2.08  0.16  2.55 -0.64  0.93\n",
      "  0.87 -1.02 -0.74  0.51 -1.03  0.01  0.49 -2.11]\n",
      "Estimation de theta par SDG SUMO: [ 0.31  1.69 -0.06 -0.95  0.59  2.3   2.07 -1.77  0.25  2.52 -0.89  1.17\n",
      "  0.61 -1.71 -0.5   0.45 -0.62  0.27 -0.22 -2.65]\n",
      "Estimation de theta par SDG RR: [-2.7   1.93  0.66 -2.84  0.36  3.03  3.2  -4.5   0.01  4.38 -1.6   1.37\n",
      "  1.05 -2.82 -2.15 -0.2  -2.87 -0.35  0.31 -4.88]\n",
      "Estimation de theta par SDG SS: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yanis\\OneDrive\\Documents\\Monte Carlo\\Projet-Monte-Carlo\\src\\estimators2.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return num/denom\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(878)\n",
    "theta_sdg=SDG(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, echantillon=echantillon_x)\n",
    "theta_iawe=SDG_IAWE(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k=6)\n",
    "theta_SUMO=SDG_SUMO(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k_max=6)\n",
    "theta_RR=SDG_RR(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k_max=6)\n",
    "theta_SS=SDG_SS(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k_max=6)\n",
    "\n",
    "print(\"Vraie valeur de theta: {}\".format(np.around(theta, 2)))\n",
    "print(\"Estimation de theta par descente de gradient stochastique useuelle: {}\".format(np.around(theta_sdg, 2)))\n",
    "print(\"Estimation de theta par SDG IWAE: {}\".format(np.around(theta_iawe, 2)))\n",
    "print(\"Estimation de theta par SDG SUMO: {}\".format(np.around(theta_SUMO, 2)))\n",
    "print(\"Estimation de theta par SDG RR: {}\".format(np.around(theta_RR, 2)))\n",
    "print(\"Estimation de theta par SDG SS: {}\".format(np.around(theta_SS, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedure_MC_theta(M, L, theta, A, b, n):\n",
    "    biais_SDG_M={}\n",
    "    biais_IWAE_M={}\n",
    "    biais_SUMO_M={}\n",
    "    biais_SS_M={}\n",
    "    biais_RR_M={}\n",
    "\n",
    "    var_SDG_M={}\n",
    "    var_IWAE_M={}\n",
    "    var_SUMO_M={}\n",
    "    var_SS_M={}\n",
    "    var_RR_M={}\n",
    "\n",
    "    l=1\n",
    "    while l<=L:\n",
    "        print(l)\n",
    "        m=1\n",
    "        estimations_SDG_M_l=np.array([])\n",
    "        estimations_IWAE_M_l=np.array([])\n",
    "        estimations_SUMO_M_l=np.array([])\n",
    "        estimations_SS_M_l=np.array([])\n",
    "        estimations_RR_M_l=np.array([])\n",
    "\n",
    "\n",
    "        while m<=M:\n",
    "            echantillon_x=generer_nech_gaussien(n)\n",
    "            theta_SDG=SDG(theta_init=np.array([0]*20), learn_rate=0.01, echantillon=echantillon_x, n_iter=100)\n",
    "            theta_IAWE=SDG_IAWE(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k=l)\n",
    "            theta_SUMO=SDG_SUMO(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "            theta_RR=SDG_RR(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "            theta_SS=SDG_SS(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "\n",
    "            if m==1:\n",
    "                estimations_SDG_M_l=np.append(estimations_SDG_M_l, theta_SDG)\n",
    "                estimations_IWAE_M_l= np.append(estimations_IWAE_M_l, theta_IAWE)\n",
    "                estimations_SUMO_M_l=np.append(estimations_SUMO_M_l, theta_SUMO)\n",
    "                estimations_RR_M_l=np.append(estimations_RR_M_l, theta_RR)\n",
    "                estimations_SS_M_l=np.append(estimations_SS_M_l, theta_SS)\n",
    "            \n",
    "            else:\n",
    "                estimations_SDG_M_l=np.vstack((estimations_SDG_M_l, theta_SDG))\n",
    "                estimations_IWAE_M_l= np.vstack((estimations_IWAE_M_l, theta_IAWE))\n",
    "                estimations_SUMO_M_l=np.vstack((estimations_SUMO_M_l, theta_SUMO))\n",
    "                estimations_RR_M_l=np.vstack((estimations_RR_M_l, theta_RR))\n",
    "                estimations_SS_M_l=np.vstack((estimations_SS_M_l, theta_SS))\n",
    "            m+=1\n",
    "\n",
    "        biais_SDG_M_l=np.mean(estimations_SDG_M_l, axis=0)-theta\n",
    "        biais_IWAE_M_l=np.mean(estimations_IWAE_M_l, axis=0)-theta\n",
    "        biais_IWAE_M_l=np.mean(estimations_IWAE_M_l, axis=0)-theta\n",
    "        biais_SUMO_M_l=np.mean(estimations_SUMO_M_l, axis=0)-theta\n",
    "        biais_SS_M_l=np.mean(estimations_SS_M_l, axis=0)-theta\n",
    "        biais_RR_M_l=np.mean(estimations_RR_M_l, axis=0)-theta\n",
    "\n",
    "        squared_biais_SDG_M_l=norm(biais_SDG_M_l)**2\n",
    "        squared_biais_IWAE_M_l=norm(biais_IWAE_M_l)**2\n",
    "        squared_biais_SUMO_M_l=norm(biais_SUMO_M_l)**2\n",
    "        squared_biais_SS_M_l=norm(biais_SS_M_l)**2\n",
    "        squared_biais_RR_M_l=norm(biais_RR_M_l)**2\n",
    "\n",
    "        var_SDG_M_l=np.mean(norm(estimations_SDG_M_l-np.mean(estimations_IWAE_M_l, axis=0))**2)\n",
    "        var_IWAE_M_l=np.mean(norm(estimations_IWAE_M_l-np.mean(estimations_IWAE_M_l, axis=0))**2)\n",
    "        var_SUMO_M_l=np.mean(norm(estimations_SUMO_M_l-np.mean(estimations_SUMO_M_l, axis=0))**2)\n",
    "        var_SS_M_l=np.mean(norm(estimations_SS_M_l-np.mean(estimations_SS_M_l, axis=0))**2)\n",
    "        var_RR_M_l=np.mean(norm(estimations_RR_M_l-np.mean(estimations_RR_M_l, axis=0))**2)\n",
    "        \n",
    "        biais_SDG_M[l]=squared_biais_SDG_M_l\n",
    "        biais_IWAE_M[l]=squared_biais_IWAE_M_l\n",
    "        biais_SUMO_M[l]=squared_biais_SUMO_M_l\n",
    "        biais_SS_M[l]=squared_biais_SS_M_l\n",
    "        biais_RR_M[l]=squared_biais_RR_M_l\n",
    "        \n",
    "        var_SDG_M[l]=var_SDG_M_l\n",
    "        var_IWAE_M[l]=var_IWAE_M_l\n",
    "        var_SUMO_M[l]=var_SUMO_M_l\n",
    "        var_SS_M[l]=var_SS_M_l\n",
    "        var_RR_M[l]=var_RR_M_l\n",
    "\n",
    "        l+=1\n",
    "\n",
    "    return biais_SDG_M, biais_IWAE_M, biais_SUMO_M, biais_SS_M, biais_RR_M, var_SDG_M,var_IWAE_M, var_SUMO_M, var_SS_M, var_RR_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(8554)\n",
    "\n",
    "# biais_SDG_M_theta, biais_IWAE_M_theta, biais_SUMO_M_theta, biais_SS_M_theta, biais_RR_M_theta, var_SDG_M_theta, var_IWAE_M_theta, var_SUMO_M_theta, var_SS_M_theta, var_RR_M_theta = procedure_MC_theta(M=1000, \n",
    "#                                                                                                                                                                                                         L=6, \n",
    "#                                                                                                                                                                                                         theta=theta, \n",
    "#                                                                                                                                                                                                         A=A, \n",
    "#                                                                                                                                                                                                         b=b,\n",
    "#                                                                                                                                                                                                         n=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
