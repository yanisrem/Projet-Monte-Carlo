{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.densite_function import *\n",
    "from src.gaussian_simulation import *\n",
    "from src.estimators2 import *\n",
    "from src.vraisemblance import *\n",
    "import numpy as np\n",
    "from numpy.linalg import norm \n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8878)\n",
    "\n",
    "theta=simulate_gaussian_vector(mu=np.array([0]*20), sigma=np.identity(20))\n",
    "z=simulate_gaussian_vector(mu=theta, sigma=np.identity(20))\n",
    "x=simulate_gaussian_vector(mu=z, sigma=np.identity(20)) #on sait simuler x|z\n",
    "\n",
    "#x=simulate_gaussian_vector(mu=theta, sigma=2*np.identity(20))\n",
    "\n",
    "A_optimal=np.identity(20)*0.5\n",
    "b_optimal=theta/2\n",
    "\n",
    "A=A_optimal+simulate_gaussian_vector(mu=np.array([0]*20), sigma=0.01*np.identity(20))\n",
    "b=b_optimal+simulate_gaussian_vector(mu=np.array([0]*20), sigma=0.01*np.identity(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On généré un n-échantillon de taille 100, de loi $p_{\\theta}(\\mathbf{x}|z)=\\mathcal{N}(z, I_{20})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8878)\n",
    "\n",
    "def generer_nech_gaussien(n):\n",
    "    i=1\n",
    "    echantillon_x=np.array([])\n",
    "\n",
    "    while i<=n:\n",
    "        z=simulate_gaussian_vector(mu=theta, sigma=np.identity(20))\n",
    "        if i==1:\n",
    "            echantillon_x=np.append(echantillon_x, simulate_gaussian_vector(mu=z, sigma=np.identity(20))) #on sait simuler x|z\n",
    "        else:\n",
    "            echantillon_x=np.vstack((echantillon_x, simulate_gaussian_vector(mu=z, sigma=np.identity(20))))\n",
    "        i+=1\n",
    "    return echantillon_x\n",
    "\n",
    "echantillon_x=generer_nech_gaussien(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La log-vraisemblance de l'échantillon (avec le facteur $-\\frac{1}{n}$) est $l_n(\\theta)=\\frac{1}{n}\\sum_{i=1}^n \\lVert X_i - \\theta \\rVert^2 = \\frac{1}{n}\\sum_{i=1}^n l_i(\\theta) $. \n",
    "On cherche $\\hat{\\theta} \\in argmin \\; l_n(\\theta)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On estime le theta de la log vraisemblance par $\\nabla_{\\theta} l_i(\\theta)= -2(X_i-\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG(theta_init, learn_rate, echantillon, n_iter):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta_init)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*(-1)*gradient_log_vraisemblance(echantillon[i], theta)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_IAWE(theta_init, learn_rate, n_iter, A, b, echantillon, k=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta_init, A=A, b=b, x=echantillon[i])\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta, A=A, b=b, x=echantillon[i])\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*importance_sampling_gradientlogvraisemblance(k=k, theta=theta, A=A, b=b, x=echantillon[i])\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_SUMO(theta_init, learn_rate, n_iter, A, b, echantillon, k_max=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta_init, A=A, b=b, x=echantillon[i], r=0.6, k_max=k_max)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta, A=A, b=b, x=echantillon[i], r=0.6, k_max=k_max)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_SUMO_gradientlogvraisemblance(theta=theta, A=A, b=b, x=echantillon[i], r=0.6, k_max=k_max)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_RR(theta_init, learn_rate, n_iter, A, b, echantillon, k_max=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta_init, A=A, b=b, r=0.6, k_max=k_max)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, k_max=k_max)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_ML_RR_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, k_max=k_max)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDG_SS(theta_init, learn_rate, n_iter, A, b, echantillon, k_max=6):\n",
    "    #Step 1: mélanger l'échantillon\n",
    "    i=0\n",
    "    compteur=0\n",
    "    np.random.shuffle(echantillon)\n",
    "    theta=theta_init-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta_init, A=A, b=b, r=0.6, k_max=k_max)\n",
    "\n",
    "    i+=1\n",
    "    compteur+=1\n",
    "    #Tant qu'on n'atteint pas le nombre d'itérations fixé, on actualise theta\n",
    "    while compteur<n_iter:\n",
    "        # Si on a parcouru tout l'échantillon alors que le nombre d'itérations n'est pas atteint,\n",
    "        # On remélange l'échantillon, on reparcourt l'échantillon en commençant par le début\n",
    "        # Le compteur n'est pas réinitialisé\n",
    "        if i==len(echantillon):\n",
    "           i=0\n",
    "           np.random.shuffle(echantillon)\n",
    "           theta=theta-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, k_max=k_max)\n",
    "           i+=1\n",
    "           compteur+=1\n",
    "        else:\n",
    "            theta=theta-learn_rate*estimateur_ML_SS_gradientlogvraisemblance(x=echantillon[i], theta=theta, A=A, b=b, r=0.6, k_max=k_max)\n",
    "            i+=1\n",
    "            compteur+=1\n",
    "\n",
    "    else:\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vraie valeur de theta: [-0.3  -1.01 -0.57  0.53 -0.45 -1.65 -1.66  1.26 -0.5  -2.16  0.18 -0.7\n",
      " -0.77  0.53  0.12 -0.5   0.69 -0.35 -0.43  1.35]\n",
      "Estimation de theta par descente de gradient stochastique useuelle: [-0.2  -0.83 -0.48  0.36 -0.49 -1.79 -1.34  1.06 -0.31 -1.59  0.25 -0.65\n",
      " -0.67  0.57  0.08 -0.27  0.52 -0.37 -0.22  1.07]\n",
      "Estimation de theta par SDG IWAE: [ 0.15  1.43  0.64 -1.    0.53  2.28  1.87 -2.08  0.16  2.55 -0.64  0.93\n",
      "  0.87 -1.02 -0.74  0.51 -1.03  0.01  0.49 -2.11]\n",
      "Estimation de theta par SDG SUMO: [ 0.56  3.26 -0.66 -3.14  1.38  5.64  4.08 -3.76  0.62  4.28 -2.26  1.9\n",
      "  1.3  -3.1  -2.14  2.12 -0.95  1.08 -0.98 -6.77]\n",
      "Estimation de theta par SDG RR: [-20.65   0.76   3.36  -4.16   1.89   3.9    1.65  -7.06   2.73   6.29\n",
      "   0.68   2.33  -0.2   -1.37  -6.76  -2.65  -1.2   -4.05   0.05  -9.52]\n",
      "Estimation de theta par SDG SS: [-12.01  -1.8   -0.17  -3.13  -0.31   1.3   -1.45  -3.41  -2.04   5.68\n",
      "  -3.13  -0.02   2.83   0.3    0.83  -0.46   3.24  -2.43  -1.2   -3.6 ]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(878)\n",
    "theta_sdg=SDG(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, echantillon=echantillon_x)\n",
    "theta_iawe=SDG_IAWE(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k=6)\n",
    "theta_SUMO=SDG_SUMO(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k_max=6)\n",
    "theta_RR=SDG_RR(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k_max=6)\n",
    "theta_SS=SDG_SS(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k_max=6)\n",
    "\n",
    "print(\"Vraie valeur de theta: {}\".format(np.around(theta, 2)))\n",
    "print(\"Estimation de theta par descente de gradient stochastique useuelle: {}\".format(np.around(theta_sdg, 2)))\n",
    "print(\"Estimation de theta par SDG IWAE: {}\".format(np.around(theta_iawe, 2)))\n",
    "print(\"Estimation de theta par SDG SUMO: {}\".format(np.around(theta_SUMO, 2)))\n",
    "print(\"Estimation de theta par SDG RR: {}\".format(np.around(theta_RR, 2)))\n",
    "print(\"Estimation de theta par SDG SS: {}\".format(np.around(theta_SS, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedure_MC_theta(M, L, theta, A, b, n):\n",
    "    biais_SDG_M={}\n",
    "    biais_IWAE_M={}\n",
    "    biais_SUMO_M={}\n",
    "    biais_SS_M={}\n",
    "    biais_RR_M={}\n",
    "\n",
    "    var_SDG_M={}\n",
    "    var_IWAE_M={}\n",
    "    var_SUMO_M={}\n",
    "    var_SS_M={}\n",
    "    var_RR_M={}\n",
    "\n",
    "    l=1\n",
    "    while l<=L:\n",
    "        print(l)\n",
    "        m=1\n",
    "        estimations_SDG_M_l=np.array([])\n",
    "        estimations_IWAE_M_l=np.array([])\n",
    "        estimations_SUMO_M_l=np.array([])\n",
    "        estimations_SS_M_l=np.array([])\n",
    "        estimations_RR_M_l=np.array([])\n",
    "\n",
    "\n",
    "        while m<=M:\n",
    "            echantillon_x=generer_nech_gaussien(n)\n",
    "            theta_SDG=SDG(theta_init=np.array([0]*20), learn_rate=0.01, echantillon=echantillon_x, n_iter=100)\n",
    "            theta_IAWE=SDG_IAWE(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, k=l)\n",
    "            theta_SUMO=SDG_SUMO(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "            theta_RR=SDG_RR(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "            theta_SS=SDG_SS(theta_init=np.array([0]*20), learn_rate=0.01, n_iter=100, A=A, b=b, echantillon=echantillon_x, l=l)\n",
    "\n",
    "            if m==1:\n",
    "                estimations_SDG_M_l=np.append(estimations_SDG_M_l, theta_SDG)\n",
    "                estimations_IWAE_M_l= np.append(estimations_IWAE_M_l, theta_IAWE)\n",
    "                estimations_SUMO_M_l=np.append(estimations_SUMO_M_l, theta_SUMO)\n",
    "                estimations_RR_M_l=np.append(estimations_RR_M_l, theta_RR)\n",
    "                estimations_SS_M_l=np.append(estimations_SS_M_l, theta_SS)\n",
    "            \n",
    "            else:\n",
    "                estimations_SDG_M_l=np.vstack((estimations_SDG_M_l, theta_SDG))\n",
    "                estimations_IWAE_M_l= np.vstack((estimations_IWAE_M_l, theta_IAWE))\n",
    "                estimations_SUMO_M_l=np.vstack((estimations_SUMO_M_l, theta_SUMO))\n",
    "                estimations_RR_M_l=np.vstack((estimations_RR_M_l, theta_RR))\n",
    "                estimations_SS_M_l=np.vstack((estimations_SS_M_l, theta_SS))\n",
    "            m+=1\n",
    "\n",
    "        biais_SDG_M_l=np.mean(estimations_SDG_M_l, axis=0)-theta\n",
    "        biais_IWAE_M_l=np.mean(estimations_IWAE_M_l, axis=0)-theta\n",
    "        biais_IWAE_M_l=np.mean(estimations_IWAE_M_l, axis=0)-theta\n",
    "        biais_SUMO_M_l=np.mean(estimations_SUMO_M_l, axis=0)-theta\n",
    "        biais_SS_M_l=np.mean(estimations_SS_M_l, axis=0)-theta\n",
    "        biais_RR_M_l=np.mean(estimations_RR_M_l, axis=0)-theta\n",
    "\n",
    "        squared_biais_SDG_M_l=norm(biais_SDG_M_l)**2\n",
    "        squared_biais_IWAE_M_l=norm(biais_IWAE_M_l)**2\n",
    "        squared_biais_SUMO_M_l=norm(biais_SUMO_M_l)**2\n",
    "        squared_biais_SS_M_l=norm(biais_SS_M_l)**2\n",
    "        squared_biais_RR_M_l=norm(biais_RR_M_l)**2\n",
    "\n",
    "        var_SDG_M_l=np.mean(norm(estimations_SDG_M_l-np.mean(estimations_IWAE_M_l, axis=0))**2)\n",
    "        var_IWAE_M_l=np.mean(norm(estimations_IWAE_M_l-np.mean(estimations_IWAE_M_l, axis=0))**2)\n",
    "        var_SUMO_M_l=np.mean(norm(estimations_SUMO_M_l-np.mean(estimations_SUMO_M_l, axis=0))**2)\n",
    "        var_SS_M_l=np.mean(norm(estimations_SS_M_l-np.mean(estimations_SS_M_l, axis=0))**2)\n",
    "        var_RR_M_l=np.mean(norm(estimations_RR_M_l-np.mean(estimations_RR_M_l, axis=0))**2)\n",
    "        \n",
    "        biais_SDG_M[l]=squared_biais_SDG_M_l\n",
    "        biais_IWAE_M[l]=squared_biais_IWAE_M_l\n",
    "        biais_SUMO_M[l]=squared_biais_SUMO_M_l\n",
    "        biais_SS_M[l]=squared_biais_SS_M_l\n",
    "        biais_RR_M[l]=squared_biais_RR_M_l\n",
    "        \n",
    "        var_SDG_M[l]=var_SDG_M_l\n",
    "        var_IWAE_M[l]=var_IWAE_M_l\n",
    "        var_SUMO_M[l]=var_SUMO_M_l\n",
    "        var_SS_M[l]=var_SS_M_l\n",
    "        var_RR_M[l]=var_RR_M_l\n",
    "\n",
    "        l+=1\n",
    "\n",
    "    return biais_SDG_M, biais_IWAE_M, biais_SUMO_M, biais_SS_M, biais_RR_M, var_SDG_M,var_IWAE_M, var_SUMO_M, var_SS_M, var_RR_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(8554)\n",
    "\n",
    "# biais_SDG_M_theta, biais_IWAE_M_theta, biais_SUMO_M_theta, biais_SS_M_theta, biais_RR_M_theta, var_SDG_M_theta, var_IWAE_M_theta, var_SUMO_M_theta, var_SS_M_theta, var_RR_M_theta = procedure_MC_theta(M=1000, \n",
    "#                                                                                                                                                                                                         L=6, \n",
    "#                                                                                                                                                                                                         theta=theta, \n",
    "#                                                                                                                                                                                                         A=A, \n",
    "#                                                                                                                                                                                                         b=b,\n",
    "#                                                                                                                                                                                                         n=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
